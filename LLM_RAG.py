# langchain_full_feature_chatbot.py

import os
import uuid
import tiktoken
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.documents import Document
from langchain_core.messages import AIMessage, HumanMessage
from ddgs.exceptions import DDGSException

from dotenv import load_dotenv

load_dotenv()

# --- âš™ï¸ ì „ì—­ ì„¤ì • ë° ì´ˆê¸°í™” ---

# 1. ëª¨ë¸ ë° í† í° ê´€ë ¨ ì„¤ì •
MAIN_LLM_MODEL = "gpt-4o"
SUB_LLM_MODEL = "gpt-3.5-turbo"
TOKENIZER = tiktoken.encoding_for_model(MAIN_LLM_MODEL)
# ëª¨ë¸ì˜ ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê³ ë ¤í•˜ì—¬, í”„ë¡¬í”„íŠ¸ì˜ ìµœëŒ€ í† í° ìˆ˜ë¥¼ ì—¬ìœ ë¡­ê²Œ ì„¤ì • (ì‘ë‹µ í† í° ê³µê°„ í™•ë³´)
PROMPT_TOKEN_LIMIT = 8000 

# 2. ì„ë² ë”© ëª¨ë¸ ë° DB ì„¤ì •
EMBEDDING_MODEL = OpenAIEmbeddings()
DB_PATH = "chroma_db_persistent"
VECTORSTORE = Chroma(persist_directory=DB_PATH, embedding_function=EMBEDDING_MODEL)

# 3. ìš”ì•½ ê´€ë ¨ ì„¤ì •
SUMMARIZATION_TRIGGER_LENGTH = 6 
NUM_PRESERVED_CONV_DOCS = 2 # ë³´ì¡´í•  ì‹œì‘ ëŒ€í™” ë¬¸ì„œ ìˆ˜ (ì²« ì§ˆë¬¸+ë‹µë³€)


# --- ğŸš€ í•µì‹¬ í•¨ìˆ˜ ì •ì˜ ---

def get_initial_analysis(diary_text: str, emotion_label: str, image_label: str) -> str:
    """ì¼ê¸° ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ˆê¸° ì¢…í•© ë¶„ì„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    print("ğŸ§  ì´ˆê¸° ë¶„ì„ ìƒì„± ì¤‘...")
    llm = ChatOpenAI(model=MAIN_LLM_MODEL, temperature=0.7)
    prompt = ChatPromptTemplate.from_template(
        """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë§ˆìŒì„ ê¹Šì´ ê³µê°í•˜ëŠ” ë”°ëœ»í•œ ì‹¬ë¦¬ ìƒë‹´ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ê±´ë„¬ ì²« ìœ„ë¡œì™€ ë¶„ì„ ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        [ì‚¬ìš©ì ì •ë³´]
        1. ì¼ê¸°: "{diary}"
        2. ê°ì •: "{emotion}"
        3. ê·¸ë¦¼: "{image}"
        ---
        [ìƒë‹´ê°€ì˜ ì²« ë¶„ì„ ë° ìœ„ë¡œ ë©”ì‹œì§€]"""
    )
    chain = prompt | llm | StrOutputParser()
    analysis = chain.invoke({"diary": diary_text, "emotion": emotion_label, "image": image_label})
    return analysis

def generate_search_queries(analysis: str, num_queries: int = 2) -> list[str]:
    """ì´ˆê¸° ë¶„ì„ ë‚´ìš©ì—ì„œ Hugging Faceì—ì„œ ê²€ìƒ‰í•  ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    print(f"\n--- ğŸ” ê²€ìƒ‰ì–´ ìƒì„± ì¤‘... ---")
    query_generator_llm = ChatOpenAI(model=SUB_LLM_MODEL)
    prompt = ChatPromptTemplate.from_template(
        "ë‹¤ìŒ ë¶„ì„ ë‚´ìš©ì˜ í•µì‹¬ ì£¼ì œì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´ {num}ê°œë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ìƒì„±í•´ì£¼ì„¸ìš”.\n\n[ë¶„ì„ ë‚´ìš©]\n{analysis}\n\n[ê²€ìƒ‰ì–´]"
    )
    chain = prompt | query_generator_llm | StrOutputParser()
    queries_str = chain.invoke({"analysis": analysis, "num": num_queries})
    queries = [q.strip() for q in queries_str.split(',')]
    print(f"--- âœ… ìƒì„±ëœ ê²€ìƒ‰ì–´: {queries} ---")
    return queries

def search_and_load_huggingface_docs(queries: list[str]) -> list[Document]:
    """ìƒì„±ëœ ê²€ìƒ‰ì–´ë¡œ Hugging Face ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ë¡œë“œí•©ë‹ˆë‹¤."""
    print(f"\n--- ğŸ“š Hugging Face ë¬¸ì„œ ê²€ìƒ‰ ë° ë¡œë”© ì¤‘... ---")
    # DuckDuckGoSearchRunì€ URL ëª©ë¡ ëŒ€ì‹  ìš”ì•½ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ,
    # ì—¬ê¸°ì„œëŠ” ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ ìì²´ë¥¼ ë¬¸ì„œë¡œ í™œìš©í•©ë‹ˆë‹¤.
    search_tool = DuckDuckGoSearchRun()
    all_docs = []
    for query in queries:
        full_query = f"{query} site:huggingface.co/docs"        
        try:
            search_results_str = search_tool.run(full_query)
            docs = [Document(page_content=search_results_str, metadata={"source": "huggingface_docs"})]
            all_docs.extend(docs)
        except DDGSException as e:
            # ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ê²½ê³  ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ê³  ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.
            print(f"âš ï¸ ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì¿¼ë¦¬: {full_query}): {e}")
            print("   ì™¸ë¶€ ë¬¸ì„œ ê²€ìƒ‰ì„ ê±´ë„ˆë›°ê³  ëŒ€í™”ë¥¼ ê³„ì†í•©ë‹ˆë‹¤.")
            continue # í˜„ì¬ ì¿¼ë¦¬ëŠ” ê±´ë„ˆë›°ê³  ë‹¤ìŒ ì¿¼ë¦¬ë¡œ ì§„í–‰
    print(f"--- âœ… ì´ {len(all_docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ ---")
    return all_docs

def summarize_conversation(docs_to_summarize: list[Document]) -> Document:
    """ì£¼ì–´ì§„ ëŒ€í™” ê¸°ë¡(Document ë¦¬ìŠ¤íŠ¸)ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•©ë‹ˆë‹¤."""
    print("\n--- ğŸ”„ ì¤‘ê°„ ëŒ€í™” ë‚´ìš© ìš”ì•½ ì¤‘... ---")
    summarizer_llm = ChatOpenAI(model=SUB_LLM_MODEL, temperature=0.2)
    history_str = "\n".join([doc.page_content for doc in docs_to_summarize])
    prompt = ChatPromptTemplate.from_template("ë‹¤ìŒ ëŒ€í™”ì˜ í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n[ëŒ€í™” ë‚´ìš©]\n{history}\n\n[ìš”ì•½]")
    chain = prompt | summarizer_llm | StrOutputParser()
    summary_text = chain.invoke({"history": history_str})
    summary_doc = Document(page_content=f"ì¤‘ê°„ ëŒ€í™” ìš”ì•½: {summary_text}", metadata={"type": "summary"})
    print(f"--- âœ… ìš”ì•½ ì™„ë£Œ: {summary_text[:50]}... ---")
    return summary_doc

def start_new_counseling_session(diary_id: int, username: str, diary_text: str, emotion_label: str, image_label: str) -> tuple[str, str]:
    """
    ìƒˆë¡œìš´ ìƒë‹´ ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤. ë¹„íšŒì› ì²˜ë¦¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    """
    is_guest = diary_id == -1 and username is None
    if is_guest:
        # ë¹„íšŒì›ì¼ ê²½ìš°, ê³ ìœ í•œ ì„ì‹œ IDë¥¼ ìƒì„±
        temp_username = f"guest_{uuid.uuid4()}"
        print(f"âœ¨ ë¹„íšŒì› ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤ (ì„ì‹œ ID: {temp_username})")
        username = temp_username
        diary_id = -1 # ë¹„íšŒì›ì˜ ì¼ê¸° IDëŠ” -1ë¡œ ìœ ì§€
    else:
        print(f"âœ¨ ìƒˆë¡œìš´ ìƒë‹´ ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤ (ID: {username}_{diary_id})")

    initial_analysis = get_initial_analysis(diary_text, emotion_label, image_label)
    search_queries = generate_search_queries(initial_analysis)
    external_docs = search_and_load_huggingface_docs(search_queries)

    docs_to_store = [
        Document(
            page_content=f"ìƒë‹´ ì‹œì‘ ë¶„ì„: {initial_analysis}",
            metadata={"username": username, "diary_id": str(diary_id), "type": "initial_analysis"}
        )
    ]
    # ì™¸ë¶€ ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°ì—ë„ ì‚¬ìš©ì ì •ë³´ë¥¼ ì¶”ê°€í•˜ì—¬ ì €ì¥
    for doc in external_docs:
        doc.metadata.update({"username": username, "diary_id": str(diary_id)})
    docs_to_store.extend(external_docs)

    VECTORSTORE.add_documents(docs_to_store)
    print("--- âœ… ì´ˆê¸° ë¶„ì„ ë° ì™¸ë¶€ ë¬¸ì„œê°€ ChromaDBì— ì˜êµ¬ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ---")
    
    # ë¹„íšŒì›ì˜ ê²½ìš°, ë‹¤ìŒ ìš”ì²­ì„ ìœ„í•´ ì„ì‹œ IDë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
    return initial_analysis, username if is_guest else ""

def get_token_count(text: str) -> int:
    """tiktokenì„ ì‚¬ìš©í•´ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    return len(TOKENIZER.encode(text))

def continue_counseling_session(diary_id: int, username: str, user_message: str) -> str:
    """
    ê¸°ì¡´ ìƒë‹´ ì„¸ì…˜ì„ ì´ì–´ê°€ë©°, ë©”íƒ€ë°ì´í„°ë¥¼ í†µí•´ ì„ ë³„ëœ ëŒ€í™” ê¸°ë¡ë§Œ ìš”ì•½í•˜ê³  RAGë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ” ê¸°ì¡´ ìƒë‹´ ì„¸ì…˜ì„ ì´ì–´ê°‘ë‹ˆë‹¤ (ID: {username}_{diary_id})")

    # 1. DBì—ì„œ í˜„ì¬ ì„¸ì…˜ì˜ ëª¨ë“  ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    filter = {"$and": [{"username": {"$eq": username}}, {"diary_id": {"$eq": str(diary_id)}}]}
    # 1. DBì—ì„œ í˜„ì¬ ì„¸ì…˜ì˜ ëª¨ë“  ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    results = VECTORSTORE.get(where=filter, include=["metadatas", "documents"])
    docs = [Document(page_content=results['documents'][i], metadata=results['metadatas'][i]) for i in range(len(results['ids']))]

    # 2. ë©”íƒ€ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œ ë¶„ë¥˜
    conv_docs, initial_doc, external_docs, summary_doc = [], None, [], None
    for doc in docs:
        if doc.metadata.get('type') == 'initial_analysis': initial_doc = doc
        elif doc.metadata.get('type') == 'summary': summary_doc = doc
        elif doc.metadata.get('source') == 'huggingface_docs': external_docs.append(doc)
        else: conv_docs.append(doc)
            
    # 3. ëŒ€í™” ê¸°ë¡ì´ ê¸¸ë©´ 'ì¤‘ê°„ ë¶€ë¶„' ìš”ì•½
    if len(conv_docs) >= SUMMARIZATION_TRIGGER_LENGTH:
        docs_to_summarize = conv_docs[NUM_PRESERVED_CONV_DOCS:-2]
        if docs_to_summarize:
            new_summary_doc = summarize_conversation(docs_to_summarize)
            new_summary_doc.metadata.update({"username": username, "diary_id": str(diary_id)})
            VECTORSTORE.delete(where={"$and": [filter, {"type": "summary"}]})
            VECTORSTORE.add_documents([new_summary_doc])
            summary_doc = new_summary_doc

            
    # 4. âœ… í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•œ ë™ì  ì»¨í…ìŠ¤íŠ¸ ì¡°ì ˆ
    final_context = ""
    prompt_template = ChatPromptTemplate.from_template(
        "ë‹¹ì‹ ì€ ë”°ëœ»í•œ ì‹¬ë¦¬ ìƒë‹´ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ 'ì°¸ê³  ìë£Œ'ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n\n"
        "[ì°¸ê³  ìë£Œ]\n{context}\n\n[ì‚¬ìš©ìì˜ ì§ˆë¬¸]\n{question}\n\n[ë‹µë³€]"
    )
    
    # Level 1: RAG ë¬¸ì„œ ê°œìˆ˜(k)ë¥¼ ì¤„ì—¬ê°€ë©° í† í° í™•ì¸
    for k in range(4, 0, -1):
        retriever = VECTORSTORE.as_retriever(search_kwargs={"k": k, "filter": filter})
        retrieved_docs = retriever.invoke(user_message)
        
        context_str = "\n\n".join([doc.page_content for doc in retrieved_docs])
        prompt_str = prompt_template.format(context=context_str, question=user_message)
        token_count = get_token_count(prompt_str)
        
        print(f"--- ğŸ” k={k}ë¡œ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹œ, ì˜ˆìƒ í† í° ìˆ˜: {token_count} ---")
        if token_count <= PROMPT_TOKEN_LIMIT:
            final_context = context_str
            print(f"--- âœ… í† í° ìˆ˜ ì•ˆì • í™•ì¸ (k={k}). ì´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ---")
            break
    
    # Level 2: ê·¸ë˜ë„ í† í°ì´ ë„˜ì¹˜ë©´, ìµœì†Œí•œì˜ ì •ë³´ë¡œ Fallback
    if not final_context:
        print("--- âš ï¸ ê²½ê³ : RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¤„ì—¬ë„ í† í° ì œí•œì„ ì´ˆê³¼í•©ë‹ˆë‹¤. ì´ˆê¸° ë¶„ì„ê³¼ í˜„ì¬ ì§ˆë¬¸ë§Œìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ---")
        final_context = initial_doc.page_content if initial_doc else "ì´ˆê¸° ë¶„ì„ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # 5. RAG ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰
    llm = ChatOpenAI(model=MAIN_LLM_MODEL, temperature=0.7)
    rag_chain = (
        {"context": lambda x: final_context, "question": RunnablePassthrough()}
        | prompt_template
        | llm
        | StrOutputParser()
    )
    ai_response = rag_chain.invoke(user_message)
    
    # 6. í˜„ì¬ ëŒ€í™”ë¥¼ DBì— ì €ì¥
    docs_to_add = [
        Document(page_content=f"ì‚¬ìš©ì ì§ˆë¬¸: {user_message}", metadata={"username": username, "diary_id": str(diary_id)}),
        Document(page_content=f"ìƒë‹´ê°€ ë‹µë³€: {ai_response}", metadata={"username": username, "diary_id": str(diary_id)})
    ]
    VECTORSTORE.add_documents(docs_to_add)
    return ai_response

def delete_counseling_history(diary_id: int, username: str):
    """íŠ¹ì • ì‚¬ìš©ìì˜ íŠ¹ì • ì¼ê¸° ëŒ€í™” ê¸°ë¡ì„ DBì—ì„œ ì‚­ì œí•©ë‹ˆë‹¤."""
    filter_to_delete = {"$and": [{"username": {"$eq": username}}, {"diary_id": {"$eq": str(diary_id)}}]}
    ids_to_delete = VECTORSTORE.get(where=filter_to_delete)['ids']
    
    if not ids_to_delete:
        print(f"ğŸ—‘ï¸ ì‚­ì œí•  ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤ (ID: {username}_{diary_id})")
        return
        
    VECTORSTORE.delete(ids=ids_to_delete)
    print(f"ğŸ—‘ï¸ {len(ids_to_delete)}ê°œì˜ ëŒ€í™” ê¸°ë¡ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤ (ID: {username}_{diary_id})")


# --- âœ… API ì„œë²„ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ (ìš”ì•½ ê¸°ëŠ¥ í¬í•¨) ---
if __name__ == "__main__":
    
    # --- ì‹œë‚˜ë¦¬ì˜¤ 1: íšŒì› ì‚¬ìš©ì (ëŒ€í™” í„´ì„ ëŠ˜ë ¤ ìš”ì•½ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸) ---
    DIARY_ID = 404
    USERNAME = "ì •íšŒì›"
    DIARY_TEXT = "í”„ë¡œì íŠ¸ ë§ˆê°ì´ ë‹¤ê°€ì˜¤ëŠ”ë°, ì˜ˆìƒì¹˜ ëª»í•œ ë²„ê·¸ê°€ ê³„ì† í„°ì ¸ì„œ ì ì„ ëª» ìê³  ìˆë‹¤. íŒ€ì›ë“¤ì—ê²Œ ë¯¸ì•ˆí•˜ê³  ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë„ˆë¬´ ì‹¬í•˜ë‹¤."
    EMOTION = "ì´ˆì¡°í•¨"
    IMAGE = "ë‹¤ íƒ€ë²„ë¦° ì–‘ì´ˆ"

    print("\n" + "="*60)
    print("API ìš”ì²­ 1: íšŒì› ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ìƒë‹´ ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    # start_new_counseling_sessionì€ (ë¶„ì„ê²°ê³¼, ì„ì‹œID)ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ, ì„ì‹œID ë¶€ë¶„ì€ _ ë¡œ ë¬´ì‹œ
    initial_response, _ = start_new_counseling_session(
        diary_id=DIARY_ID, 
        username=USERNAME, 
        diary_text=DIARY_TEXT,
        emotion_label=EMOTION,
        image_label=IMAGE
    )
    print("\nğŸ’¬ ìƒë‹´ê°€ì˜ ì´ˆê¸° ë¶„ì„:\n", initial_response)
    print("="*60)

    # ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ ì§ˆë¬¸ ëª©ë¡
    questions = [
        "ì œ ìƒí™©ì„ ì–´ë–»ê²Œ í•´ê²°í•˜ë©´ ì¢‹ì„ì§€ ë§‰ë§‰í•´ìš”.",
        "í˜¼ì í•´ê²°í•˜ë ¤ë‹ˆ ë” í˜ë“  ê²ƒ ê°™ì•„ìš”. íŒ€ì›ë“¤ì—ê²Œ ì–´ë–»ê²Œ ë§í•˜ëŠ” ê²Œ ì¢‹ì„ê¹Œìš”?",
        "ì¢‹ì€ ì¡°ì–¸ì´ë„¤ìš”. í•˜ì§€ë§Œ ì œê°€ ë²„ê·¸ì— ëŒ€í•´ ë§í–ˆì„ ë•Œ íŒ€ì›ë“¤ì´ ë¶€ì •ì ìœ¼ë¡œ ë°˜ì‘í• ê¹Œ ë´ ê±±ì •ë¼ìš”.",
        "ì•Œê² ìŠµë‹ˆë‹¤, ìš©ê¸°ë¥¼ ë‚´ë³¼ê²Œìš”. ê·¸ê²ƒê³¼ ë³„ê°œë¡œ ì§€ê¸ˆ ë‹¹ì¥ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ë°©ë²•ì´ ìˆì„ê¹Œìš”?"
    ]

    for i, q in enumerate(questions):
        print("\n" + "="*60)
        # í„´ ë²ˆí˜¸ëŠ” 1ë¶€í„° ì‹œì‘ (iëŠ” 0ë¶€í„° ì‹œì‘)
        turn_number = i + 1
        print(f"API ìš”ì²­ {turn_number + 1}: íšŒì› ì‚¬ìš©ìê°€ í›„ì† ì§ˆë¬¸ {turn_number}ì„(ë¥¼) ë³´ëƒ…ë‹ˆë‹¤.")
        print(f"   ì‚¬ìš©ì: {q}")

        # í„´ 3 ì´í›„ (ì´ ë¬¸ì„œ ê°œìˆ˜ê°€ 8ê°œë¥¼ ë„˜ì–´ì„œëŠ” ì‹œì )ë¶€í„° ìš”ì•½ ê¸°ëŠ¥ì´ ë™ì‘í•  ê²ƒì„ ê¸°ëŒ€
        if (1 + (turn_number * 2)) >= SUMMARIZATION_TRIGGER_LENGTH:
             print("   (ì°¸ê³ : ëŒ€í™” ê¸°ë¡ì´ ê¸¸ì–´ì ¸ì„œ ì´ë²ˆ í„´ë¶€í„° ìš”ì•½ ê¸°ëŠ¥ì´ ë™ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")
        
        response = continue_counseling_session(
            diary_id=DIARY_ID, 
            username=USERNAME, 
            user_message=q
        )
        print("\nğŸ’¬ ìƒë‹´ê°€:\n", response)
        print("="*60)


    # --- ì‹œë‚˜ë¦¬ì˜¤ 2: ë¹„íšŒì› ì‚¬ìš©ì ---
    GUEST_DIARY_TEXT = "ì˜¤ëŠ˜ ê¸¸ì„ ê°€ë‹¤ê°€ ì˜ˆìœ ê³ ì–‘ì´ë¥¼ ë´¤ë‹¤. ê¸°ë¶„ì´ ì¢‹ì•„ì¡Œë‹¤."
    
    print("\n" + "="*60)
    print("API ìš”ì²­ (ë¹„íšŒì›): ë¹„íšŒì› ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ìƒë‹´ ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    guest_initial_response, guest_temp_id = start_new_counseling_session(-1, None, GUEST_DIARY_TEXT, "ê¸°ì¨", "ì›ƒëŠ” ê³ ì–‘ì´")
    print(f"\nğŸ’¬ ìƒë‹´ê°€ì˜ ì´ˆê¸° ë¶„ì„ (ì„ì‹œ ID: {guest_temp_id}):\n", guest_initial_response)
    print("="*60)
    
    # --- ì‹œë‚˜ë¦¬ì˜¤ 3: ê¸°ë¡ ì‚­ì œ ---
    print("\n" + "="*60)
    print("API ìš”ì²­ (ì‚­ì œ): íšŒì› ì‚¬ìš©ìì˜ ëŒ€í™” ê¸°ë¡ì„ ì‚­ì œí•©ë‹ˆë‹¤.")
    delete_counseling_history(DIARY_ID, USERNAME)
    delete_counseling_history(-1, guest_temp_id)
    print("="*60)